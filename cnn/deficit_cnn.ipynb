{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deficit_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cu8i3DsN4lHV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AHbbsfhq7eEq"
      },
      "source": [
        "###Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrwDc8WSW1-v",
        "colab_type": "code",
        "outputId": "cd3b2771-24b0-4697-feb6-72e069c38ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sXBU9J-cPZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XodRkmXj4VVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "#import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3kqWRyfwc3Z",
        "colab_type": "text"
      },
      "source": [
        "###Silence Warnings\n",
        "- 0: all messages are logged (default behavior)\n",
        "- 1: INFO messages are not printed\n",
        "- 2: INFO and WARNING messages are not printed\n",
        "- 3: INFO, WARNING, and ERROR messages are not printed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2N2_KNFwcfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXt8jbid4Zzd",
        "colab_type": "text"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNf32Dd6WpOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deficit_cnn_model(features, labels, mode):\n",
        "\n",
        "    ''' Input Layer '''\n",
        "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
        "    input_layer = tf.reshape(features, [-1, 50, 5, 1])\n",
        "\n",
        "    ''' Convolutional Layer #1 '''\n",
        "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
        "    #   Padding is added to preserve width and height.\n",
        "    # Tensor Shape: [batch_size, 50, 5, 32]\n",
        "    conv1 = tf.layers.conv2d(\n",
        "        inputs = input_layer,\n",
        "        filters = 32,\n",
        "        kernel_size = [5, 5],\n",
        "        padding = \"same\",\n",
        "        activation = tf.nn.relu\n",
        "    )\n",
        "\n",
        "    ''' Pooling Layer #1 '''\n",
        "    # Max pooling layer with a 2x2 filter and stride of 2\n",
        "    # Tensor Shape: [batch_size, 25, 2, 32]\n",
        "    pool1 = tf.layers.max_pooling2d(\n",
        "        inputs = conv1,\n",
        "        pool_size = [2, 2],\n",
        "        strides = 2\n",
        "    )\n",
        "\n",
        "    ''' Convolutional Layer #2 '''\n",
        "    # Computes 64 features using a 5x5 filter.\n",
        "    #   Padding is added to preserve width and height.\n",
        "    # Tensor Shape: [batch_size, 25, 2, 64]\n",
        "    conv2 = tf.layers.conv2d(\n",
        "        inputs = pool1,\n",
        "        filters = 64,\n",
        "        kernel_size = [5, 5],\n",
        "        padding = \"same\",\n",
        "        activation = tf.nn.relu\n",
        "    )\n",
        "\n",
        "    ''' Pooling Layer #2 '''\n",
        "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
        "    # Tensor Shape: [batch_size, 12, 1, 64]\n",
        "    pool2 = tf.layers.max_pooling2d(\n",
        "        inputs = conv2,\n",
        "        pool_size = [2, 2],\n",
        "        strides = 2\n",
        "    )\n",
        "\n",
        "    ''' Flatten tensor into a batch of vectors '''\n",
        "    # Output Tensor Shape: [batch_size, 768]\n",
        "    pool2_flat = tf.reshape(pool2, [-1, 12 * 64])\n",
        "\n",
        "    ''' Dense Layer '''\n",
        "    # Densely connected layer with 1024 neurons\n",
        "    # Tensor Shape: [batch_size, 1024]\n",
        "    dense = tf.layers.dense(\n",
        "        inputs = pool2_flat,\n",
        "        units = 1024,\n",
        "        activation = tf.nn.relu\n",
        "    )\n",
        "    \n",
        "    ''' Add dropout operation '''\n",
        "    # 0.6 probability that element will be kept\n",
        "    # Tensor Shape: [batch_size, 1024]\n",
        "    dropout = tf.layers.dropout(\n",
        "        inputs = dense,\n",
        "        rate = 0.4,\n",
        "        training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    )\n",
        "\n",
        "\n",
        "    ''' Logits layer '''\n",
        "    # Input Tensor Shape: [batch_size, 1024]\n",
        "    # Tensor Shape: [batch_size, 1024]\n",
        "    logits = tf.layers.dense(\n",
        "        inputs = dropout,\n",
        "        units = 10\n",
        "    )\n",
        "\n",
        "    predictions = {\n",
        "        # Generate predictions (for PREDICT and EVAL mode)\n",
        "        \"classes\": tf.argmax(input=logits, axis=1),\n",
        "\n",
        "        # Add `softmax_tensor` to the graph.\n",
        "        # It is used for PREDICT and by the `logging_hook`.\n",
        "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "\n",
        "    # Configure the Training Op (for TRAIN mode)\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
        "        train_op = optimizer.minimize(\n",
        "            loss = loss,\n",
        "            global_step = tf.train.get_global_step()\n",
        "        )\n",
        "\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode = mode,\n",
        "            loss = loss,\n",
        "            train_op = train_op\n",
        "        )\n",
        "\n",
        "    # Add evaluation metrics (for EVAL mode)\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\": tf.metrics.accuracy(\n",
        "            labels = labels,\n",
        "            predictions = predictions[\"classes\"]\n",
        "        )\n",
        "    }\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode = mode,\n",
        "        loss = loss,\n",
        "        eval_metric_ops = eval_metric_ops\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BifdneGnqGz4",
        "colab_type": "text"
      },
      "source": [
        "##Load Data and Setup Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peTWxyaU4e9N",
        "colab_type": "text"
      },
      "source": [
        "###Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHyUGD7uYm58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape: [606, 250]\n",
        "train_data = np.loadtxt(path + \"training_set_80.txt\")\n",
        "train_labels = np.loadtxt(path + \"training_labels_80.txt\", dtype = np.int32)\n",
        "\n",
        "eval_data = np.loadtxt(path + \"training_set_80.txt\")\n",
        "eval_labels = np.loadtxt(path + \"training_labels_80.txt\", dtype = np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8i3DsN4lHV",
        "colab_type": "text"
      },
      "source": [
        "###Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLYom4HUpW0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
        "logging_hook = tf.train.LoggingTensorHook(\n",
        "    tensors = tensors_to_log,\n",
        "    every_n_iter = 50\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AS-aCIavEc7",
        "colab_type": "text"
      },
      "source": [
        "##Create Estimator and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9d2TMXRpqDe",
        "colab_type": "text"
      },
      "source": [
        "###Create Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAKzY479Y0P0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "ed72d276-ddd8-49b6-ba53-2b93bc9479e2"
      },
      "source": [
        "classifier = tf.estimator.Estimator(model_fn = deficit_cnn_model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzbfgg33t\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzbfgg33t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f591156e6d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "miR0udQm7dNe"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tb-Ua4Jh7e1t",
        "colab": {}
      },
      "source": [
        "# Shape: [606, 50, 5, 1]\n",
        "input_layer = tf.reshape(train_data, [-1, 50, 5, 1])\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = train_data,\n",
        "    y = train_labels,\n",
        "    batch_size = 10,\n",
        "    num_epochs = None,\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-g_WPM1M7R3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "0ce74488-4eec-4c0a-ab91-7ae5ce559fc5"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn = train_input_fn,\n",
        "    steps = 1000,\n",
        "    #hooks = [logging_hook]\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-5-f451f57f20cc>:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-f451f57f20cc>:25: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-f451f57f20cc>:59: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-f451f57f20cc>:68: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpzbfgg33t/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.2975096702575684, step = 0\n",
            "INFO:tensorflow:global_step/sec: 165.655\n",
            "INFO:tensorflow:loss = 1.8169111013412476, step = 100 (0.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.924\n",
            "INFO:tensorflow:loss = 1.1255850791931152, step = 200 (0.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.16\n",
            "INFO:tensorflow:loss = 0.6284241080284119, step = 300 (0.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.966\n",
            "INFO:tensorflow:loss = 0.8836380243301392, step = 400 (0.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.304\n",
            "INFO:tensorflow:loss = 0.5916515588760376, step = 500 (0.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 230.281\n",
            "INFO:tensorflow:loss = 0.7376644015312195, step = 600 (0.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.951\n",
            "INFO:tensorflow:loss = 0.7284903526306152, step = 700 (0.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.253\n",
            "INFO:tensorflow:loss = 0.6245607137680054, step = 800 (0.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.34\n",
            "INFO:tensorflow:loss = 0.7535338401794434, step = 900 (0.437 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpzbfgg33t/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.7644284963607788.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f5908946c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss6A-67c19CE",
        "colab_type": "text"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz7EBVAJY659",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "0601187c-9741-487b-ee02-2ba77cdd0a4e"
      },
      "source": [
        "# Evaluate the model and print results\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = eval_data,\n",
        "    y = eval_labels,\n",
        "    num_epochs = 1,\n",
        "    shuffle = False\n",
        ")\n",
        "eval_results = classifier.evaluate(input_fn = eval_input_fn)\n",
        "print(eval_results)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-31T03:05:35Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpzbfgg33t/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-31-03:05:35\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.5247525, global_step = 1000, loss = 0.7020097\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpzbfgg33t/model.ckpt-1000\n",
            "{'accuracy': 0.5247525, 'loss': 0.7020097, 'global_step': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}